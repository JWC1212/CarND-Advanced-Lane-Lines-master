{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "with open('obj_pts.p', 'rb') as f:\n",
    "    objpoints = pickle.load(f)\n",
    "with open('img_pts.p', 'rb') as f:\n",
    "    imgpoints =pickle.load(f)\n",
    "with open(\"M.p\", \"rb\") as f:\n",
    "    M = pickle.load(f)\n",
    "with open(\"inverseM.p\", \"rb\") as f:\n",
    "    inverseM = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get X or Y gradient via Sobel Operator.\n",
    "def get_abs_Sobel_grad(gray_img, sobel_kernel=5, direction = 'X'):\n",
    "    if direction == 'X':\n",
    "        sobelx=cv2.Sobel(gray_img, cv2.CV_64F, 1, 0,sobel_kernel)\n",
    "        return np.absolute(sobelx)\n",
    "    elif direction =='Y':\n",
    "        sobely=cv2.Sobel(gray_img, cv2.CV_64F, 0, 1,sobel_kernel)\n",
    "        return np.absolute(sobely)\n",
    "    else:\n",
    "        print('Please set gradient direction parameter: X or Y?')\n",
    "        return gray_img\n",
    "\n",
    "#Scale the gradient image.\n",
    "def get_scaled_Sobel(abs_sobel_img):\n",
    "    return np.uint8(255*abs_sobel_img/np.max(abs_sobel_img))\n",
    "\n",
    "#get binary image of gradient.\n",
    "def binary_Sobel(scaled_img, threshold=(20, 100)):\n",
    "    binary_sobel = np.zeros_like(scaled_img)\n",
    "    binary_sobel[(scaled_img>=threshold[0])&(scaled_img<=threshold[1])]=1\n",
    "    return binary_sobel\n",
    "\n",
    "#get binary image of gradient's magnitude\n",
    "def binary_Magnitude(abs_sobelx, abs_sobely, threshold=(20, 100)):    \n",
    "    sobelxy = np.sqrt(np.square(abs_sobelx)+np.square(abs_sobely)) \n",
    "    scaled_sobelxy = np.uint8(255*sobelxy/np.max(sobelxy))\n",
    "    binary_sobelxy = np.zeros_like(scaled_sobelxy)\n",
    "    binary_sobelxy[(scaled_sobelxy >= threshold[0]) & (scaled_sobelxy <= threshold[1])] = 1\n",
    "    return binary_sobelxy\n",
    "\n",
    "#get binary image of direction of gradient\n",
    "def binary_Dir_Grad(abs_sobelx, abs_sobely, arc_threshold=(0.7, 1.3)):\n",
    "    dir_grad = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    binary_dir_grad = np.zeros_like(dir_grad)\n",
    "    binary_dir_grad[(dir_grad>=arc_threshold[0]) & (dir_grad<=arc_threshold[1])] = 1\n",
    "    return binary_dir_grad\n",
    "                    \n",
    "def combine_Binary_Grad(binary_sbx, binary_sby, binary_mag, binary_dir_grad):\n",
    "    binary_Comb_Grad = np.zeros_like(binary_sbx)\n",
    "    binary_Comb_Grad[((binary_sbx==1)&(binary_sby==1))|((binary_mag==1)&(binary_dir_grad==1))] = 1\n",
    "    return binary_Comb_Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_HLS_channel(undist_img, channel='S', threshold=(0,255)):\n",
    "    HLS_img = cv2.cvtColor(undist_img, cv2.COLOR_BGR2HLS)\n",
    "    if channel=='H':\n",
    "        H = HLS_img[:,:,0]\n",
    "        binary_H = np.zeros_like(H)\n",
    "        binary_H[(H>=threshold[0])&(H<=threshold[1])]=1\n",
    "        return binary_H\n",
    "    elif channel=='L':\n",
    "        L = HLS_img[:,:,1]\n",
    "        binary_L = np.zeros_like(L)\n",
    "        binary_L[(L>=threshold[0])&(L<=threshold[1])]=1\n",
    "        return binary_L\n",
    "    elif channel=='S':\n",
    "        S = HLS_img[:,:,2]\n",
    "        binary_S = np.zeros_like(S)\n",
    "        binary_S[(S>=threshold[0])&(S<=threshold[1])]=1\n",
    "        return binary_S\n",
    "    else:\n",
    "        print('Please choose one channel parameter of H, L or S?')\n",
    "        return undist_img\n",
    "def combine_HS(binary_H, binary_S):\n",
    "    binary_HS = np.zeros_like(binary_H)\n",
    "    binary_HS[(binary_H ==1)&(binary_S ==1)] = 1\n",
    "    return binary_HS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_Binary(binary_color, binary_grad):\n",
    "    color_grad_comb = np.zeros_like(binary_grad)\n",
    "    color_grad_comb[(binary_color==1) | (binary_grad==1)]=1\n",
    "    return color_grad_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function calculates points of lanes for fitting curve.\n",
    "def calc_Lane_Points(binary_Combine):\n",
    "    mid_height = np.int(binary_Combine.shape[0]/2)\n",
    "    histogram = np.sum(binary_Combine[mid_height:,:],axis=0)\n",
    "    mid_width = np.int(histogram.shape[0]/2)\n",
    "    print(\"The middle point of image:{}\".format(mid_width))\n",
    "    leftx_base = np.argmax(histogram[:mid_width])\n",
    "    rightx_base = np.argmax(histogram[mid_width:]) + mid_width\n",
    "    print(\"Max value at x-{} left part.\".format(leftx_base))\n",
    "    print(\"Max value at x-{} right part.\".format(rightx_base))\n",
    "    nonzero = np.nonzero(binary_Combine)\n",
    "    nonzerox = nonzero[1]\n",
    "    nonzeroy = nonzero[0]\n",
    "    nwindows = 9\n",
    "    height = binary_Combine.shape[0]\n",
    "    win_height = np.int(binary_Combine.shape[0]/nwindows)\n",
    "    margin = 100\n",
    "    minpixel = 50\n",
    "    #These two empty lists store indexes of nonzero pixels in nonzerox and nonzeroy.\n",
    "    left_lane_index = []\n",
    "    right_lane_index = []\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    for window in range(nwindows):\n",
    "        win_y_low = height - (window+1)*win_height\n",
    "        win_y_high = height - window*win_height\n",
    "        win_leftx_left = leftx_current - margin\n",
    "        win_leftx_right = leftx_current + margin\n",
    "        win_rightx_left = rightx_current - margin\n",
    "        win_rightx_right = rightx_current + margin\n",
    "        good_left_ind=((nonzeroy>=win_y_low)&(nonzeroy<win_y_high)&(nonzerox>=win_leftx_left)&(nonzerox<win_leftx_right)).nonzero()[0]\n",
    "        good_right_ind=((nonzeroy>=win_y_low)&(nonzeroy<win_y_high)&(nonzerox>=win_rightx_left)&(nonzerox<win_rightx_right)).nonzero()[0]\n",
    "        left_lane_index.append(good_left_ind)\n",
    "        right_lane_index.append(good_right_ind)\n",
    "        if len(good_left_ind) > minpixel:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_ind]))\n",
    "        if len(good_right_ind) > minpixel:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_ind]))\n",
    "    left_lane_index = np.concatenate(left_lane_index)\n",
    "    right_lane_index = np.concatenate(right_lane_index)\n",
    "\n",
    "    leftx = nonzerox[left_lane_index]\n",
    "    lefty = nonzeroy[left_lane_index] \n",
    "    rightx = nonzerox[right_lane_index]\n",
    "    righty = nonzeroy[right_lane_index]\n",
    "    return leftx, lefty, rightx, righty\n",
    "\n",
    "#This function gets left and right lanes via A*y*y+B*y+C which returns A, B and C coefficients.\n",
    "def fit_Lanes(leftx, lefty, rightx, righty):\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    return left_fit, right_fit\n",
    "\n",
    "#This function calculates the whole lanes using fit coefficients A, B, C\n",
    "def calc_X(binary_Combine, left_fit, right_fit):\n",
    "    ploty = np.linspace(0, binary_Combine.shape[0]-1, binary_Combine.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    return left_fitx, right_fitx\n",
    "\n",
    "#This function calculates the radius of curve.\n",
    "def converse_CurveradToMeter(left_fitx, right_fitx, y_eval, ym_per_pix=30/720, xm_per_pix=3.7/700):\n",
    "    #ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    #xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    ploty = np.linspace(0, 719, 720)\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undistortImage(image, objpts, imgpts):\n",
    "    ret, cameraMat, distortCoef,rvecs, tvecs = cv2.calibrateCamera(objpts, imgpts, (image.shape[1],image.shape[0]), None, None)\n",
    "    undist_img = cv2.undistort(image, cameraMat, distortCoef, None, cameraMat)\n",
    "    return undist_img\n",
    "\n",
    "def process_image(img, First_Frame = True):\n",
    "    undist = undistortImage(img, objpoints, imgpoints)\n",
    "    warped_img = cv2.warpPerspective(undist, M, (1280, 720))\n",
    "    gray_warped = cv2.cvtColor(warped_img, cv2.COLOR_RGB2GRAY)\n",
    "    '''gradient threshold'''\n",
    "    warped_sobelx = get_abs_Sobel_grad(gray_warped, sobel_kernel=5, direction = 'X')\n",
    "    #warped_sobely = get_abs_Sobel_grad(gray_warped, sobel_kernel=5, direction = 'Y')\n",
    "    scaled_warped_sobelx = get_scaled_Sobel(warped_sobelx)\n",
    "    #scaled_warped_sobely = get_scaled_Sobel(warped_sobely)\n",
    "\n",
    "    binary_warped_sobelx = binary_Sobel(scaled_warped_sobelx, threshold=(20, 100))\n",
    "    #binary_warped_sobely = binary_Sobel(scaled_warped_sobely, threshold=(20, 100))\n",
    "    #binary_mag = binary_Magnitude(warped_sobelx, warped_sobely, threshold=(28, 141))\n",
    "    #binary_dir_grad = binary_Dir_Grad(warped_sobelx, warped_sobely, arc_threshold=(1.0, np.pi/2))\n",
    "    #binary_grad = combine_Binary_Grad(binary_warped_sobelx, binary_warped_sobely, binary_mag, binary_dir_grad)\n",
    "    '''color threshold'''\n",
    "    binary_S = get_HLS_channel(warped_img, threshold=(170,255))\n",
    "    binary_H = get_HLS_channel(warped_img, 'H',threshold=(70,100))\n",
    "    #binary_L = get_HLS_channel(warped_img, 'L',threshold=(24,200))\n",
    "    binary_HS = combine_HS(binary_H, binary_S)\n",
    "    \n",
    "    binary_Combine = combine_Binary(binary_HS, binary_warped_sobelx)\n",
    "    \n",
    "    if First_Frame:\n",
    "        #detected pixels on lanes\n",
    "        leftx, lefty, rightx, righty = calc_Lane_Points(binary_Combine)\n",
    "        First_Frame = False\n",
    "    else:\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        margin = 100\n",
    "        left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "        left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "        left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "\n",
    "        right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "        right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "        right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "        # Again, extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # Fit a second order polynomial to each.calculates coefficients\n",
    "    left_fit, right_fit = fit_Lanes(leftx, lefty, rightx, righty)\n",
    "    #calculate x position of lanes via coefficients\n",
    "    left_fitx, right_fitx = calc_X(binary_Combine, left_fit, right_fit)\n",
    "    \n",
    "    ploty = np.linspace(0, binary_Combine.shape[0]-1, binary_Combine.shape[0])\n",
    "    #calculate radius of curve\n",
    "    left_curverad, right_curverad = converse_CurveradToMeter(left_fitx, right_fitx, y_eval = 719, ym_per_pix=30/720, xm_per_pix=3.7/700)\n",
    "    left_text = \"The radius of the left lane is \" + str(left_curverad)+ ' meters.'\n",
    "    right_text = \"The radius of the right lane is \" + str(right_curverad) + \" meters.\"\n",
    "    \n",
    "    center_lane = (right_fitx[719]+left_fitx[719])/2.0\n",
    "    offset = (center_lane - 1280/2.0-1)*3.7/700\n",
    "    if offset <= 0:    \n",
    "        offset_text = \"The vehicle is \"+str(np.abs(offset))+\" meters left of center.\"\n",
    "    else:\n",
    "        offset_text = \"The vehicle is \"+str(offset)+\" meters right of center.\"\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_Combine).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, inverseM, (1280, 720)) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    cv2.putText(result, left_text, (100,50), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 1, False)\n",
    "    cv2.putText(result, right_text, (100,100), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 1, False)\n",
    "    cv2.putText(result, offset_text, (100,150), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 1, False)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The middle point of image:640\n",
      "Max value at x-343 left part.\n",
      "Max value at x-1043 right part.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'binary_Combine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d34e5bb39eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#clip1 = VideoFileClip(\"../project_video.mp4\").subclip(0,5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclip1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../project_video.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mwhite_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#NOTE: this function expects color images!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time white_clip.write_videofile(video_output, audio=False)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wuhao/anaconda/lib/python3.6/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mfl_image\u001b[0;34m(self, image_func, apply_to)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wuhao/anaconda/lib/python3.6/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mfl\u001b[0;34m(self, fun, apply_to, keep_duration)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-178>\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n",
      "\u001b[0;32m/Users/wuhao/anaconda/lib/python3.6/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36moutplace\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnewclip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wuhao/anaconda/lib/python3.6/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \"\"\"\n\u001b[1;32m    693\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-135>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "\u001b[0;32m/Users/wuhao/anaconda/lib/python3.6/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wuhao/anaconda/lib/python3.6/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wuhao/anaconda/lib/python3.6/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wuhao/anaconda/lib/python3.6/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-9285ae078110>\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(img, First_Frame)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mploty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_Combine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_Combine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m#calculate radius of curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mleft_curverad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_curverad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverse_CurveradToMeter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m719\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mym_per_pix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m720\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxm_per_pix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3.7\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mleft_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The radius of the left lane is \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_curverad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m' meters.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mright_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The radius of the right lane is \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_curverad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" meters.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-118917d35fcf>\u001b[0m in \u001b[0;36mconverse_CurveradToMeter\u001b[0;34m(left_fitx, right_fitx, y_eval, ym_per_pix, xm_per_pix)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m#ym_per_pix = 30/720 # meters per pixel in y dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m#xm_per_pix = 3.7/700 # meters per pixel in x dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mploty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_Combine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_Combine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;31m# Fit new polynomials to x,y in world space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mleft_fit_cr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mploty\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mym_per_pix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_fitx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxm_per_pix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'binary_Combine' is not defined"
     ]
    }
   ],
   "source": [
    "video_output = \"../output_images/project_video_output.mp4\"\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"../project_video.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"../project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(video_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
